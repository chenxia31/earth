{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Constructing kernels\n",
    "In class, we saw that by choosing a kernel $K(x, z) = \\phi(x).T \\phi(z)$, we can implicitly map data to a high dimensional space, and have the SVM algorithm work in that space. One way to generate kernels is to explicitly define the mapping $\\phi$ to a higher dimensional space, and then work out the corresponding K.\n",
    "However in this question we are interested in direct construction of kernels. I.e., suppose we have a function $K(x, z)$ that we think gives an appropriate similarity measure for our learning problem, and we are considering plugging $K$ into the SVM as the kernel function. However for $K(x,z)$ to be a valid kernel, it must correspond to an inner product in some higher dimensional space resulting from some feature mapping $\\phi$. Mercer's theorem tells us that $K(x,z)$ is a (Mercer) kernel if and only if for any finite set $\\{x^{(1)}, \\ldots , x^{(m)}\\}$, the square matrix $K\\in \\mathbb{R}^{m\\times m}$ whose entries are given by $K_{ij} = K(x^{(i)},x^{(j)})$ is symmetric and positive semidefinite. You can find more details about Mercer’s theorem in the notes, though the description above is sufficient for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here comes the question: Let $K_1, K_2$ be kernels over $\\mathbb{R}^n\\times \\mathbb{R}^n$, let $a\\in \\mathbb{R}^+$ be a positive real number, let $f:\\mathbb{R}^n\\rightarrow \\mathbb{R}$ be a real-valued function, let $\\phi:\\mathbb{R}^n\\rightarrow \\mathbb{R}^d$ be a function mapping from $\\mathbb{R}^n$ to $\\mathbb{R}^d$, let $K_3$ be a kernel over $\\mathbb{R}^d\\times \\mathbb{R}^d$, and let $p(x)$ a polynomial over $x$ with positive coefficients.\n",
    "\n",
    "For each of the functions $K$ below, state whether it is necessarily a kernel. If you think it is, prove it; if you think it isn't, give a counter-example.\n",
    "\n",
    "\n",
    "<b>Hint:</b> For part (e), the answer is that K is indeed a kernel. You still have to prove it, though. (This one may be harder than the rest.) This result may also be useful for another part of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(a)</b> [1 points] $K(x, z) = K_1(x, z) + K_2(x, z)$\n",
    "\n",
    "### Answer: \n",
    "Yes. Using Mercer's theorem, $K(x,z)$ is a kernel, since the sum of two symetric positive semidefinite matrix is a symetric positive semidefinite matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(b)</b> [1 points] $K(x, z) = K_1(x, z) − K_2(x, z)$\n",
    "\n",
    "### Answer:\n",
    "Not necessarily. For instance, assume that $K_1(x, z) = x^T.y$. If we set  $K_2(x, z)= 2K_1(x, z)$, then $K(x, z) = -x^T.y$ which is not clearly a Kernel since Mercer's theorem does not hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(c)</b> [1 points] $K(x, z) = aK_1(x, z)$\n",
    "\n",
    "### Answer: \n",
    "Yes. Indeed, a positive multiplication of a symetric positive semidefinite matrix is a symetric positive semidefinite matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(d)</b> [1 points] $K(x, z) = −aK_1(x, z)$\n",
    "\n",
    "### Answer:\n",
    "No. A negative multiplication of a symetric positive semidefinite matrix is not a positive semidefinite matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(e)</b> [5 points] $K(x, z) = K_1(x, z)K_2(x, z)$\n",
    "\n",
    "### Answer:\n",
    "We should prove that, for any finite set $\\{x^{(1)}, \\ldots , x^{(m)}\\}$, the square matrix $K\\in \\mathbb{R}^{m\\times m}$ whose entries are given by $K_{ij} = K(x^{(i)},x^{(j)})$ is symmetric and positive semidefinite. Since $K_1$ and $K_2$ are symmetric and positive semidefinite, thera are $S_1,S_2\\in\\mathbb{R}^{m\\times m}$ such that $K_1=S_1S_1^T$ and $K_2=S_2S_2^T$. \n",
    "To prove that $K$ is positive semidefinite, it suffices to show that $zKz^T\\geq 0$ for each  $z\\in \\mathbb{R}^m$. \n",
    "For a given vector $z\\in \\mathbb{R}^m$, we have \n",
    "    \n",
    "\\begin{align*}\n",
    "zKz^T \n",
    "& = zK_1\\circ K_2 z^T\\\\\n",
    "& = z(S_1S_1^t)\\circ(S_2S_2^t)z^T\\\\\n",
    "& = z(S_1\\circ S_2)(S_1\\circ S_2)^Tz^T\\\\\n",
    "& = z(S_1\\circ S_2)(S_1\\circ S_2)^Tz^T\\\\\n",
    "& = \\|z(S_1\\circ S_2)\\|_2^2\\\\\n",
    "&\\geq 0,\\\\\n",
    "\\end{align*}\n",
    "where $\\circ$ refers to elementwise product of two matrices (the Hadamard product)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>It is noticable that in general, we have the follwoing theorem. \n",
    "    \n",
    "<b>Theorem (Schur product theorem).</b> \n",
    "The Hadamard product of two positive (semi)definite matrices is also a positive definite matrix.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(f)__ [3 points] $K(x,z) = f(x)f(z)$\n",
    "\n",
    "### <font color=red> Answer:</font>\n",
    "<font color=blue>\n",
    "We should prove that, for any finite set $\\{x^{(1)}, \\ldots , x^{(m)}\\}$, the square matrix $K\\in \\mathbb{R}^{m\\times m}$ whose entries are given by $K_{ij} = K(x^{(i)},x^{(j)})$ is symmetric and positive semidefinite.\n",
    "To prove that $K$ is positive semidefinite, it suffices to show that $zKz^T\\geq 0$ for each  $z\\in \\mathbb{R}^m$. \n",
    "For a given vector $z\\in \\mathbb{R}^m$, we have \n",
    "    \n",
    "\\begin{align*}\n",
    "zKz^T \n",
    "& = \\sum_i\\sum_j z_iK(x^{i},x^{(j)})z_j\\\\\n",
    "& = \\sum_i\\sum_j z_if(x^{(i)})f(x^{(j)})z_j\\\\\n",
    "& = \\sum_i z_if(x^{(i)})\\sum_jf(x^{(j)})z_j\\\\\n",
    "& = \\left(\\sum_i z_if(x^{(i)})\\right)^2\\\\\n",
    "&\\geq 0.\\\\\n",
    "\\end{align*}\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(g)__ [3 points] $K(x, z) = K_3(\\phi(x), \\phi(z))$\n",
    "\n",
    "### <font color=red> Answer:</font>\n",
    "<font color=blue>\n",
    "Yes. Here $K$ is a valid kernel since for any finite set $\\{x^{(1)}, \\ldots , x^{(m)}\\}\\subset \\mathbb{R}^d$, the square matrix $K\\in \\mathbb{R}^{m\\times m}$ whose entries are given by $K_{ij} = K_3(x^{(i)},x^{(j)})$ is symmetric and positive semidefinite and it does not matter that these $x^{(j)}$'s are came through a mapping $\\phi(\\cdot)$. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(h)__ [3 points] $K(x, z) = p(K_1(x, z))$\n",
    "\n",
    "### <font color=red> Answer:</font>\n",
    "<font color=blue>\n",
    "Yes. Using (a), (c), and (e), we can simply prove it.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
