{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3. PCA\n",
    "\n",
    "\n",
    "In class, we showed that PCA finds the \"variance maximizing\" directions onto which to project the data. In this problem, we find another interpretation of PCA.\n",
    "\n",
    "Suppose we are given a set of points $\\{x^{(1)}, \\ldots, x^{(m)}\\}$. Let us assume that we have as usual preprocessed the data to have zero-mean and unit variance in each coordinate. For a given unit-length vector $u$, let $f_u(x)$ be the projection of point $x$ onto the direction given by $u$. I.e., if $\\mathcal{V}=\\{\\alpha u: u\\in \\mathbb{R}\\}$, then\n",
    "\n",
    "\\begin{align*}\n",
    "f_{\\mathcal{V}}(x) = \\arg\\min_{v\\in \\mathcal{V}} \\|x - v\\|_2^2.\n",
    "\\end{align*}\n",
    "\n",
    "Show that the unit-length vector u that minimizes the mean squared error between projected points and original points corresponds to the first principal component for the data. I.e., show\n",
    "that\n",
    "\n",
    "\\begin{align*}\n",
    "\\arg\\min_{u: uu^T=1} \\sum_{i=1}^m\\|x^{(i)} - f_u(x^{(i)})\\|_2^2.\n",
    "\\end{align*}\n",
    "\n",
    "gives the first principal component.\n",
    "\n",
    "\n",
    "__Remark.__ If we are asked to find a $k$-dimensional subspace onto which to project the data so as to minimize the sum of squares distance between the original data and their projections, then we should choose the $k$-dimensional subspace spanned by the first $k$ principal components of the data. This problem shows that this result holds for the case of $k=1$.\n",
    "\n",
    "### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In waht follows, we prove the statement in general case described in Remark. \n",
    "Suppose we are given a set of points $\\{x^{(1)}, \\ldots, x^{(m)}\\}\\subset \\mathbb{R}^n$ and \n",
    "$\\mathcal{V}$ is a $k$ dimensional subspace. Also, let $u_1,\\ldots,u_n$ be $n$ pairwise orthogonal unitary vectors such that $u_1,\\ldots,u_k$ sppan $\\mathcal{V}$. For a given $x$, we can write \n",
    "\n",
    "\\begin{align*}\n",
    "x = \\sum_{i=1}^n <x,u_i>u_i.\n",
    "\\end{align*}\n",
    "\n",
    "Lets first compute $f_{\\mathcal{V}}(x)$.\n",
    "\n",
    "\\begin{align*}\n",
    "\\|x - v\\|_2^2\n",
    "& = \\left\\|\\sum_{i=1}^n <x,u_i>u_i - \\sum_{i=1}^k <v,u_i>u_i\\right\\|_2^2\\\\ \\\\\n",
    "& = \\left\\|\\sum_{i=1}^k (<x,u_i>-<v,u_i>)u_i + \\sum_{i=k+1}^n <x,u_i>u_i\\right\\|_2^2\\\\ \\\\\n",
    "& = \\sum_{i=1}^k (<x,u_i>-<v,u_i>)^2 + \\sum_{i=k+1}^n <x,u_i>^2\\\\ \\\\\n",
    "& \\geq \\sum_{i=k+1}^n <x,u_i>^2\n",
    "\\end{align*}\n",
    "\n",
    "and equality holds if and only if \n",
    "$v = \\sum_{i=1}^k <x,u_i>u_i$ which means that $f_{\\mathcal{V}}(x) = \\sum_{i=1}^k <x,u_i>u_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plug it into our objective function, we obtain\n",
    "\n",
    "\\begin{align*}\n",
    "\\arg\\min_{\\mathcal{V}: \\dim(\\mathcal{V}) = k} \\sum_{i=1}^m\\|x^{(i)} - f_u(x^{(i)})\\|_2^2 \n",
    "& = \\arg\\min_{\\mathcal{V}: \\dim(\\mathcal{V}) = k} \\sum_{i=1}^m\\left\\|x^{(i)} - \\sum_{i=1}^k <x^{(i)},u_i>u_i \\right\\|_2^2\\\\ \\\\\n",
    "& = \\arg\\min_{\\mathcal{V}: \\dim(\\mathcal{V}) = k} \\sum_{i=1}^m\\left(\\|x^{(i)}\\|^2_2 - \\|\\sum_{i=1}^k <x^{(i)},u_i>u_i\\|^2_2\\right)\\\\ \\\\\n",
    "& = \\arg\\max_{\\mathcal{V}: \\dim(\\mathcal{V}) = k} \\sum_{i=1}^m\\|\\sum_{i=1}^k <x^{(i)},u_i>u_i\\|_2^2\\\\ \\\\\n",
    "& = \\arg\\max_{\\mathcal{V}: \\dim(\\mathcal{V}) = k} \\sum_{i=1}^m\\frac{1}{m}\\sum_{i=1}^k <x^{(i)},u_i>^2.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the proof since the last equality is the same objective as what we have in variance maximizing problem. Note that second equality holds since $u_1,\\ldots,u_k$ are pairwise orthogonal unitary vectors. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
